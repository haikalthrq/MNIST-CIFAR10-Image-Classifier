{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library yang dibutuhkan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurasi perangkat (menggunakan GPU jika tersedia, jika tidak menggunakan CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isAvailable:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('isAvailable: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing data dan augmentasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Augmentasi data (random cropping)\n",
    "    transforms.RandomHorizontalFlip(),     # Augmentasi data (flip horizontal)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalisasi data\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalisasi data uji\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load dataset CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Model Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Konvolusi pertama\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # Konvolusi kedua\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # Konvolusi ketiga\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)  # Konvolusi keempat\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Max pooling\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout dengan probabilitas 0.5\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 1024)  # Fully connected layer pertama\n",
    "        self.fc2 = nn.Linear(1024, 512)  # Fully connected layer kedua\n",
    "        self.fc3 = nn.Linear(512, 10)  # Fully connected layer untuk output (10 kelas)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Konvolusi pertama + ReLU + MaxPool\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Konvolusi kedua + ReLU + MaxPool\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Konvolusi ketiga + ReLU + MaxPool\n",
    "        x = self.pool(F.relu(self.conv4(x)))  # Konvolusi keempat + ReLU + MaxPool\n",
    "        \n",
    "        x = x.view(-1, 512 * 2 * 2)  # Flatten fitur map\n",
    "        \n",
    "        x = F.relu(self.fc1(x))  # Fully connected pertama + ReLU\n",
    "        x = self.dropout(x)  # Dropout untuk mencegah overfitting\n",
    "        x = F.relu(self.fc2(x))  # Fully connected kedua + ReLU\n",
    "        x = self.fc3(x)  # Fully connected untuk output (tanpa aktivasi, langsung ke softmax nantinya)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inisialisasi Model, Loss function, Optimizer, dan Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita bisa menggunakan **CrossEntropyLoss** untuk loss function dan menggunakan **Adam** untuk optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Scheduler untuk learning rate\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fungsi Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Mengatur gradien menjadi nol\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Menghitung loss\n",
    "        loss.backward()  # Backward pass (menghitung gradien)\n",
    "        optimizer.step()  # Mengupdate parameter model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    print(f'Train Loss: {running_loss / len(train_loader):.4f}, Accuracy: {100. * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Tidak perlu menghitung gradien selama testing\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    print(f'Test Loss: {test_loss / len(test_loader):.4f}, Accuracy: {100. * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Validasi dan Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\n",
      "Train Loss: 1.6774, Accuracy: 36.97%\n",
      "Test Loss: 1.3131, Accuracy: 52.45%\n",
      "Epoch [2/100]\n",
      "Train Loss: 1.2206, Accuracy: 55.89%\n",
      "Test Loss: 1.0702, Accuracy: 61.26%\n",
      "Epoch [3/100]\n",
      "Train Loss: 1.0166, Accuracy: 63.98%\n",
      "Test Loss: 0.9338, Accuracy: 66.87%\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.8887, Accuracy: 69.06%\n",
      "Test Loss: 0.7754, Accuracy: 72.92%\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.8053, Accuracy: 72.09%\n",
      "Test Loss: 0.7348, Accuracy: 74.66%\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.7457, Accuracy: 74.14%\n",
      "Test Loss: 0.7195, Accuracy: 74.81%\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.6945, Accuracy: 75.98%\n",
      "Test Loss: 0.6626, Accuracy: 77.19%\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.6586, Accuracy: 77.17%\n",
      "Test Loss: 0.6785, Accuracy: 76.43%\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.6277, Accuracy: 78.50%\n",
      "Test Loss: 0.6352, Accuracy: 77.66%\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.6064, Accuracy: 79.05%\n",
      "Test Loss: 0.6250, Accuracy: 77.63%\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.5075, Accuracy: 82.41%\n",
      "Test Loss: 0.5432, Accuracy: 81.16%\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.4751, Accuracy: 83.57%\n",
      "Test Loss: 0.5352, Accuracy: 81.32%\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.4660, Accuracy: 83.87%\n",
      "Test Loss: 0.5336, Accuracy: 81.27%\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.4523, Accuracy: 84.22%\n",
      "Test Loss: 0.5311, Accuracy: 81.33%\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.4432, Accuracy: 84.61%\n",
      "Test Loss: 0.5271, Accuracy: 81.75%\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.4356, Accuracy: 84.90%\n",
      "Test Loss: 0.5219, Accuracy: 81.87%\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.4359, Accuracy: 84.79%\n",
      "Test Loss: 0.5202, Accuracy: 81.86%\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.4240, Accuracy: 85.08%\n",
      "Test Loss: 0.5272, Accuracy: 81.75%\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.4218, Accuracy: 85.27%\n",
      "Test Loss: 0.5186, Accuracy: 81.96%\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.4132, Accuracy: 85.53%\n",
      "Test Loss: 0.5252, Accuracy: 81.88%\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.3994, Accuracy: 86.01%\n",
      "Test Loss: 0.5145, Accuracy: 82.23%\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.3979, Accuracy: 85.82%\n",
      "Test Loss: 0.5132, Accuracy: 82.28%\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.3960, Accuracy: 86.05%\n",
      "Test Loss: 0.5132, Accuracy: 82.28%\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.3938, Accuracy: 86.14%\n",
      "Test Loss: 0.5143, Accuracy: 82.24%\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.3951, Accuracy: 85.99%\n",
      "Test Loss: 0.5126, Accuracy: 82.30%\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.3962, Accuracy: 86.06%\n",
      "Test Loss: 0.5124, Accuracy: 82.30%\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.3921, Accuracy: 86.27%\n",
      "Test Loss: 0.5116, Accuracy: 82.37%\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.3952, Accuracy: 86.07%\n",
      "Test Loss: 0.5117, Accuracy: 82.37%\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.3945, Accuracy: 86.20%\n",
      "Test Loss: 0.5120, Accuracy: 82.42%\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.3932, Accuracy: 86.31%\n",
      "Test Loss: 0.5107, Accuracy: 82.47%\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.3890, Accuracy: 86.42%\n",
      "Test Loss: 0.5109, Accuracy: 82.50%\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.3886, Accuracy: 86.37%\n",
      "Test Loss: 0.5111, Accuracy: 82.49%\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.3930, Accuracy: 86.12%\n",
      "Test Loss: 0.5112, Accuracy: 82.48%\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.3922, Accuracy: 86.21%\n",
      "Test Loss: 0.5111, Accuracy: 82.46%\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.3878, Accuracy: 86.45%\n",
      "Test Loss: 0.5113, Accuracy: 82.45%\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.3876, Accuracy: 86.39%\n",
      "Test Loss: 0.5113, Accuracy: 82.53%\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.3892, Accuracy: 86.34%\n",
      "Test Loss: 0.5113, Accuracy: 82.52%\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.3897, Accuracy: 86.33%\n",
      "Test Loss: 0.5112, Accuracy: 82.47%\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.3910, Accuracy: 86.19%\n",
      "Test Loss: 0.5113, Accuracy: 82.45%\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.3937, Accuracy: 86.10%\n",
      "Test Loss: 0.5114, Accuracy: 82.47%\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.3890, Accuracy: 86.25%\n",
      "Test Loss: 0.5114, Accuracy: 82.51%\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.3893, Accuracy: 86.39%\n",
      "Test Loss: 0.5114, Accuracy: 82.49%\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.3861, Accuracy: 86.30%\n",
      "Test Loss: 0.5114, Accuracy: 82.51%\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.3937, Accuracy: 86.06%\n",
      "Test Loss: 0.5114, Accuracy: 82.50%\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.3909, Accuracy: 86.41%\n",
      "Test Loss: 0.5113, Accuracy: 82.49%\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.3898, Accuracy: 86.25%\n",
      "Test Loss: 0.5113, Accuracy: 82.50%\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.3884, Accuracy: 86.35%\n",
      "Test Loss: 0.5113, Accuracy: 82.51%\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.3930, Accuracy: 86.19%\n",
      "Test Loss: 0.5113, Accuracy: 82.50%\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.3881, Accuracy: 86.39%\n",
      "Test Loss: 0.5113, Accuracy: 82.48%\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.3890, Accuracy: 86.24%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.3893, Accuracy: 86.38%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.3896, Accuracy: 86.40%\n",
      "Test Loss: 0.5113, Accuracy: 82.48%\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.3854, Accuracy: 86.23%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.3888, Accuracy: 86.42%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.3905, Accuracy: 86.25%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.3869, Accuracy: 86.48%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.3862, Accuracy: 86.42%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.3916, Accuracy: 86.22%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.3893, Accuracy: 86.42%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.3886, Accuracy: 86.30%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.3911, Accuracy: 86.23%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.3859, Accuracy: 86.50%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.3878, Accuracy: 86.48%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.3825, Accuracy: 86.38%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.3895, Accuracy: 86.10%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.3869, Accuracy: 86.39%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.3927, Accuracy: 86.21%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.3869, Accuracy: 86.45%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.3881, Accuracy: 86.37%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.3862, Accuracy: 86.42%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.3864, Accuracy: 86.32%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.3896, Accuracy: 86.32%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.3872, Accuracy: 86.48%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.3906, Accuracy: 86.54%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.3900, Accuracy: 86.30%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.3899, Accuracy: 86.39%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.3823, Accuracy: 86.39%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.3889, Accuracy: 86.41%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.3872, Accuracy: 86.40%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.3878, Accuracy: 86.41%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.3855, Accuracy: 86.54%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.3884, Accuracy: 86.46%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.3884, Accuracy: 86.53%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.3916, Accuracy: 86.36%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.3898, Accuracy: 86.24%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.3905, Accuracy: 86.30%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.3855, Accuracy: 86.47%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.3854, Accuracy: 86.35%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.3934, Accuracy: 86.16%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.3877, Accuracy: 86.46%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.3876, Accuracy: 86.43%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.3858, Accuracy: 86.37%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.3910, Accuracy: 86.29%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.3903, Accuracy: 86.29%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.3875, Accuracy: 86.47%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.3914, Accuracy: 86.35%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.3880, Accuracy: 86.41%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.3887, Accuracy: 86.27%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.3875, Accuracy: 86.29%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.3860, Accuracy: 86.42%\n",
      "Test Loss: 0.5113, Accuracy: 82.47%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    train(model, train_loader, criterion, optimizer, device)\n",
    "    test(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
